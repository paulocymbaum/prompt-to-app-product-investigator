# Product Investigator Chatbot with Groq Integration

A conversational AI system that investigates product ideas through interactive questioning, maintains conversation context using RAG, and generates comprehensive prompts following best practices in software engineering.

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- Node.js 16+
- Groq API Key (free at [console.groq.com](https://console.groq.com))

### 1. Get Your Groq API Key (2 minutes)

1. Sign up at [https://console.groq.com](https://console.groq.com) (free, no credit card)
2. Go to [API Keys](https://console.groq.com/keys)
3. Click "Create API Key"
4. Copy your key (starts with `gsk_`)

### 2. Install & Configure

```bash
# Clone repository
git clone <your-repo-url>
cd lovable_prompt_generator

# Backend setup
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Quick configuration (interactive)
cd ..
./setup_groq_key.sh

# OR manual configuration
cd backend
cp .env.example .env
nano .env  # Add: GROQ_API_KEY=gsk_your_key_here
```

### 3. Run the Application

```bash
# Terminal 1 - Backend
cd backend
python -m uvicorn app:app --reload --host 0.0.0.0 --port 8000

# Terminal 2 - Frontend
cd frontend
npm install
npm run dev
```

### 4. Start Investigating!

- Open: http://localhost:5173
- Click "Start Investigation"
- Answer questions about your product
- Generate comprehensive prompt
- Export as PDF or Markdown

---

## ğŸ“– Documentation

### For Users
- **[HOW_TO_USE_GROQ.md](./HOW_TO_USE_GROQ.md)** - Quick start guide
- **[GROQ_SETUP_GUIDE.md](./GROQ_SETUP_GUIDE.md)** - Comprehensive setup guide
- **[ENV_SETUP_QUICK_REF.md](./ENV_SETUP_QUICK_REF.md)** - Environment reference

### For Developers
- **[GROQ_INTEGRATION_COMPLETE.md](./GROQ_INTEGRATION_COMPLETE.md)** - Technical details
- **[system_design.md](./system_design.md)** - System architecture
- **[requirements.md](./requirements.md)** - Business requirements
- **API Docs**: http://localhost:8000/docs (when running)

---

## âœ¨ Features

### Core Functionality
- ğŸ¤– **AI-Powered Investigation**: Contextual questions adapt to your answers
- ğŸ’¾ **RAG Memory System**: Conversation context preserved using vector storage
- ğŸ“Š **LangGraph Visualization**: Visual representation of conversation flow
- ğŸ“ **Prompt Generation**: Comprehensive prompts following SOLID/DRY principles
- ğŸ“„ **Export Options**: PDF and Markdown export
- ğŸ”„ **Session Management**: Save and resume investigations

### LLM Integration
- âš¡ **Groq Cloud**: Ultra-fast inference with free tier
- ğŸ¤– **OpenAI**: Support for GPT models
- ğŸ”€ **Provider Switching**: Easy switching between providers
- ğŸ“Š **Model Selection**: Choose from multiple models
- ğŸ”’ **Secure Storage**: Encrypted API key storage

### Technical Features
- ğŸ” **Token Encryption**: Fernet encryption for API keys
- âœ… **Format Validation**: Automatic token format checking
- ğŸ”„ **Retry Logic**: Exponential backoff for reliability
- ğŸ“¡ **Streaming Responses**: Real-time response streaming
- ğŸ¨ **Modern UI**: Clean, responsive interface
- ğŸ§ª **Comprehensive Testing**: Integration test suite included

---

## ğŸ› ï¸ Configuration

### Environment Variables

Create `backend/.env` with:

```bash
# Required: At least one API key
GROQ_API_KEY=gsk_your_key_here
OPENAI_API_KEY=sk_your_key_here  # Optional

# Provider configuration
ACTIVE_PROVIDER=groq
GROQ_SELECTED_MODEL=llama-3.3-70b-versatile

# Application settings
ENVIRONMENT=development
LOG_LEVEL=INFO
```

See `backend/.env.example` for all options.

### Available Models

| Model | Description | Context | Best For |
|-------|-------------|---------|----------|
| `llama-3.3-70b-versatile` | Latest Llama 3.3 | 8K | General purpose â­ |
| `llama-3.1-8b-instant` | Fast, lightweight | 8K | Quick responses |
| `mixtral-8x7b-32768` | Large context | 32K | Long conversations |
| `gemma-7b-it` | Efficient | 8K | Balanced |

---

## ğŸ§ª Testing

### Validate Configuration
```bash
cd backend
./validate_env.sh
```

### Run Integration Tests
```bash
cd backend
./test_groq_integration.sh
```

Tests cover:
- âœ… API key validation
- âœ… Model fetching
- âœ… Chat session creation
- âœ… Message sending
- âœ… LLM response generation

### Run Unit Tests
```bash
cd backend
pytest tests/ -v --cov=.
```

---

## ğŸ—ï¸ Architecture

### Backend
- **Framework**: FastAPI
- **LLM Integration**: LangChain (ChatGroq, ChatOpenAI)
- **Memory**: RAG with FAISS vector store
- **Storage**: File-based (Markdown conversations)
- **Security**: Fernet encryption for API keys

### Frontend
- **Framework**: React 18 with Vite
- **UI**: Tailwind CSS + shadcn/ui
- **State Management**: React Context API
- **Graph Visualization**: React Flow

### Data Flow
```
User â†’ Frontend â†’ FastAPI Routes â†’ Services
  â†“
ConfigService (Token management)
  â†“
ModelChecker (Validation)
  â†“
LLMService (LangChain)
  â†“
ChatGroq/ChatOpenAI
  â†“
Groq/OpenAI API
```

---

## ğŸ”’ Security

### Best Practices
- âœ… API keys encrypted at rest (Fernet)
- âœ… Token format validation
- âœ… Secure storage in `.env` (gitignored)
- âœ… No logging of sensitive data
- âœ… HTTPS support for API calls

### Recommendations
- Use different keys for dev/staging/prod
- Rotate keys regularly
- Monitor usage in provider dashboards
- Never commit `.env` to version control

---

## ğŸ“Š Project Structure

```
lovable_prompt_generator/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                      # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â”œâ”€â”€ .env.example                # Configuration template
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ config_service.py       # Token management
â”‚   â”‚   â”œâ”€â”€ llm_service.py          # LLM integration
â”‚   â”‚   â”œâ”€â”€ model_checker.py        # Model validation
â”‚   â”‚   â”œâ”€â”€ conversation_service.py # Chat orchestration
â”‚   â”‚   â””â”€â”€ rag_service.py          # Memory & context
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ config_routes.py        # Configuration API
â”‚   â”‚   â””â”€â”€ chat_routes.py          # Chat API
â”‚   â”œâ”€â”€ tests/                      # Test suite
â”‚   â”œâ”€â”€ validate_env.sh             # Environment validator
â”‚   â””â”€â”€ test_groq_integration.sh    # Integration tests
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/             # React components
â”‚   â”‚   â”œâ”€â”€ services/               # API clients
â”‚   â”‚   â””â”€â”€ hooks/                  # Custom hooks
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docs/                           # Documentation
â”œâ”€â”€ setup_groq_key.sh               # Interactive setup
â”œâ”€â”€ show_groq_summary.sh            # Implementation summary
â”œâ”€â”€ GROQ_SETUP_GUIDE.md             # User guide
â”œâ”€â”€ HOW_TO_USE_GROQ.md              # Quick start
â””â”€â”€ GROQ_INTEGRATION_COMPLETE.md    # Technical details
```

---

## ğŸš€ Deployment

### Docker (Recommended)

```bash
# Build and run
docker-compose up -d

# Check logs
docker-compose logs -f

# Stop
docker-compose down
```

### Manual Deployment

```bash
# Backend
cd backend
gunicorn app:app -w 4 -k uvicorn.workers.UvicornWorker

# Frontend
cd frontend
npm run build
# Serve build/ with your web server
```

---

## ğŸ› Troubleshooting

### "No API token configured"
**Solution**: Run `./setup_groq_key.sh` or add key via Settings UI

### "Invalid token format"
**Problem**: Key doesn't match expected format
**Solution**: 
- Groq keys must start with `gsk_`
- OpenAI keys start with `sk-` or `sk-proj-`
- Generate new key if needed

### "Failed to fetch models"
**Causes**: Invalid key, network issue, or provider issue
**Solution**:
```bash
# Test your key directly
curl https://api.groq.com/openai/v1/models \
  -H "Authorization: Bearer YOUR_API_KEY"
```

### Backend won't start
**Solution**:
```bash
# Check dependencies
pip install -r requirements.txt

# Check port
lsof -i :8000  # Kill if needed

# Check logs
tail -f app.log
```

### More Help
- Run diagnostics: `cd backend && ./validate_env.sh`
- Test integration: `cd backend && ./test_groq_integration.sh`
- Check API docs: http://localhost:8000/docs
- Read full guide: [GROQ_SETUP_GUIDE.md](./GROQ_SETUP_GUIDE.md)

---

## ğŸ¤ Contributing

### Development Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r backend/requirements.txt
cd frontend && npm install

# Run tests
cd backend
pytest tests/ -v

# Run with test configuration
export $(grep -v '^#' .env.test | xargs)
./test_groq_integration.sh
```

### Code Quality

- Follow SOLID principles
- Apply DRY (Don't Repeat Yourself)
- Write tests for new features
- Document public APIs
- Use type hints (Python)

---

## ğŸ“œ License

[Your License Here]

---

## ğŸ™ Acknowledgments

- **Groq**: Ultra-fast LLM inference
- **LangChain**: LLM orchestration framework
- **FastAPI**: Modern Python web framework
- **React**: UI framework

---

## ğŸ“ Support

### Resources
- **Groq Console**: https://console.groq.com
- **API Keys**: https://console.groq.com/keys
- **Groq Docs**: https://console.groq.com/docs
- **Status Page**: https://status.groq.com

### Local Documentation
- Setup Guide: `GROQ_SETUP_GUIDE.md`
- Quick Start: `HOW_TO_USE_GROQ.md`
- API Docs: http://localhost:8000/docs

### Community
- [Issues](your-repo-url/issues)
- [Discussions](your-repo-url/discussions)

---

## ğŸ¯ Roadmap

- [ ] Multi-language support
- [ ] Voice input/output
- [ ] Team collaboration features
- [ ] Advanced RAG with hybrid search
- [ ] Integration with project management tools
- [ ] AI-powered code generation
- [ ] Prompt optimization engine

---

**Ready to start?** Run `./setup_groq_key.sh` and begin investigating! ğŸš€

---

*Last Updated: November 17, 2025*
*Version: 1.0.0*
*Status: âœ… Production Ready*
