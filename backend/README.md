# Product Investigator Chatbot - Backend

LLM-powered chatbot backend for investigating product ideas and generating comprehensive development prompts using LangChain, FastAPI, and RAG.

## Features

- ğŸ¤– Multi-provider LLM support (Groq Cloud, OpenAI)
- ğŸ’¬ Conversational product investigation
- ğŸ§  RAG-based conversation memory
- ğŸ“ Comprehensive prompt generation
- ğŸ“Š LangGraph visualization
- ğŸ’¾ Session management and persistence
- ğŸ”’ Secure API token encryption
- ğŸš€ FastAPI with async support

## Prerequisites

- Python 3.9 or higher
- pip (Python package manager)
- Virtual environment (recommended)
- Groq Cloud or OpenAI API key

## Installation

### 1. Clone the repository

```bash
git clone <repository-url>
cd lovable_prompt_generator/backend
```

### 2. Create virtual environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure environment

```bash
cp .env.example .env
```

Edit `.env` and add your API keys:

```env
GROQ_API_KEY=your-groq-api-key-here
OPENAI_API_KEY=your-openai-api-key-here
SECRET_KEY=your-secret-encryption-key-here
```

## Running the Application

### Development Mode

```bash
python app.py
```

Or with uvicorn directly:

```bash
uvicorn app:app --reload --host 0.0.0.0 --port 8000
```

### Docker

```bash
# Build and run
docker-compose up --build

# Run in background
docker-compose up -d

# Stop
docker-compose down
```

### Production Mode

```bash
uvicorn app:app --host 0.0.0.0 --port 8000 --workers 4
```

## API Documentation

Once running, access the interactive API documentation:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

## Project Structure

```
backend/
â”œâ”€â”€ app.py                  # FastAPI application entry point
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ Dockerfile             # Docker configuration
â”œâ”€â”€ docker-compose.yml     # Docker Compose configuration
â”œâ”€â”€ .env.example           # Environment variables template
â”œâ”€â”€ models/                # Pydantic data models
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conversation.py   # Conversation models
â”‚   â””â”€â”€ provider.py       # Provider models
â”œâ”€â”€ routes/                # API route handlers
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ services/              # Business logic services
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ utils/                 # Utility functions
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ tests/                 # Unit and integration tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ conftest.py       # Pytest fixtures
â””â”€â”€ data/                  # Data storage (gitignored)
    â”œâ”€â”€ conversations/    # Markdown conversation files
    â”œâ”€â”€ sessions/         # Session state files
    â””â”€â”€ vectors/          # FAISS vector store
```

## API Endpoints

### System
- `GET /` - Root endpoint
- `GET /health` - Health check

### Configuration (Coming Soon)
- `POST /api/config/token` - Set API token
- `GET /api/config/models` - List available models
- `POST /api/config/model/select` - Select model

### Chat (Coming Soon)
- `POST /api/chat/start` - Start investigation
- `POST /api/chat/message` - Send message
- `GET /api/chat/history/:sessionId` - Get history

### Prompts (Coming Soon)
- `GET /api/prompt/generate/:sessionId` - Generate prompt

### Sessions (Coming Soon)
- `POST /api/session/save` - Save session
- `GET /api/session/load/:sessionId` - Load session

## Testing

### Run all tests

```bash
pytest
```

### Run with coverage

```bash
pytest --cov=. --cov-report=html
```

### Run specific test file

```bash
pytest tests/test_config_service.py
```

## Development Guidelines

### Code Style

- Follow PEP 8
- Use type hints
- Write docstrings (Google style)
- Keep functions small and focused

### SOLID Principles

- **S**ingle Responsibility: Each service has one clear purpose
- **O**pen/Closed: Extend via inheritance, not modification
- **L**iskov Substitution: Derived classes maintain base contracts
- **I**nterface Segregation: Small, focused interfaces
- **D**ependency Inversion: Depend on abstractions

### DRY Principle

- Avoid code duplication
- Use utility functions for common operations
- Create reusable components

## Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `GROQ_API_KEY` | Groq Cloud API key | - |
| `OPENAI_API_KEY` | OpenAI API key | - |
| `SECRET_KEY` | Encryption secret | - |
| `LOG_LEVEL` | Logging level | INFO |
| `ENVIRONMENT` | Environment (development/production) | development |
| `DATA_DIR` | Data storage directory | ./data |
| `API_RATE_LIMIT` | Rate limit (req/min) | 100 |
| `DEFAULT_PROVIDER` | Default LLM provider | groq |
| `DEFAULT_TEMPERATURE` | LLM temperature | 0.7 |
| `RAG_TOP_K` | RAG retrieval count | 5 |

## Troubleshooting

### Import Errors

Make sure virtual environment is activated and dependencies are installed:

```bash
source venv/bin/activate
pip install -r requirements.txt
```

### Port Already in Use

Change the port in `.env` or kill the process:

```bash
# Find process
lsof -i :8000

# Kill process
kill -9 <PID>
```

### Docker Issues

```bash
# Clean rebuild
docker-compose down -v
docker-compose build --no-cache
docker-compose up
```

## Contributing

1. Create a feature branch
2. Make changes following code style guidelines
3. Write/update tests
4. Run tests and ensure >80% coverage
5. Submit pull request

## License

[Your License Here]

## Support

For issues and questions, please open a GitHub issue or contact the maintainers.
